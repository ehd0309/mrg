version: '3.8'

services:
  # OLLAMA API
  ollama-api:
    container_name: pds-ollama
    build:
      context: ./api-ollama
      dockerfile: Dockerfile
    image: pds-ollama:latest
    ports:
      - "10669:11434"
    environment:
      - OLLAMA_KEEP_ALIVE=1m
    volumes:
      - ./api-ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: ["gpu"]
    networks:
      - park

  # OCR API
  ocr-api:
    container_name: pds-ocr
    image: pds-ocr:latest
    build:
      context: ./api-ocr
      dockerfile: Dockerfile
    environment:
      - NVIDIA_VISIBLE_DEVICES=1
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    ports:
      - "10671:5000"
    volumes:
      - ./api-ocr/assets:/app/assets
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: ["gpu"]
    networks:
      - park
  # Transformer jupyter env
  tf-jupyter:
    build:
      context: ./api-tf
      dockerfile: Dockerfile
      target: jupyter-runner
    container_name: pds-tf-jup
    image: pds-tf-jup:latest
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=2
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CHOWN_HOME=yes
      - CHOWN_HOME_OPTS=-R
      - PORT=8888
    user: root
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["2"]
              capabilities: ["gpu"]
    ports:
      - "10672:8888"
    volumes:
      - ./api-tf/workspace:/workspace
      - ./api-tf/.hf-cache:/usr/.hf-cache
    networks:
      - park
networks:
  park:
    external: true